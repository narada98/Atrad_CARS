{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "# ratings = ratings.map(lambda x: {\n",
    "#     \"movie_title\": x[\"movie_title\"],\n",
    "#     \"timestamp\": x[\"timestamp\"],\n",
    "#     \"user_id\": x[\"user_id\"],\n",
    "#     \"user_rating\": x[\"user_rating\"]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = tf.data.Dataset.load(\"../../data/portfolios_tfds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'SEMB'>,\n",
       " 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
       " 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Diversified Financials'>,\n",
       " 'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-696600287-VN/00'>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'S M B LEASING PLC'>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(portfolios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3847"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = portfolios.shuffle(5000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(int(len(portfolios)*0.8))\n",
    "test = shuffled.skip(int(len(portfolios)*0.8)).take(int(len(portfolios)*0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save(\"../../data/train\")\n",
    "test.save(\"../../data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = portfolios.batch(10000).map(lambda x: x[\"STOCKCODE\"])\n",
    "item_names = portfolios.batch(10000).map(lambda x: x[\"STOCKNAME\"])\n",
    "item_GICS = portfolios.batch(10000).map(lambda x: x[\"GICS\"])\n",
    "\n",
    "user_ids = portfolios.batch(10000).map(lambda x: x[\"CDSACCNO\"])\n",
    "\n",
    "unique_item_ids = np.unique(np.concatenate(list(items_ids)))\n",
    "unique_item_names = np.unique(np.concatenate(list(item_names)))\n",
    "unique_item_gics = np.unique(np.concatenate(list(item_GICS)))\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# need these to initialize timestamp embedding layers in future steps\n",
    "\n",
    "timestamps = np.concatenate(list(portfolios.map(lambda x: x[\"UNIX_TS\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this handles embedding user Identifiers and contextual data.\n",
    "time stamp is used as the contexual information here.\n",
    "using timestamp is \n",
    "'''\n",
    "\n",
    "class UserModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_timestamp,\n",
    "        unique_user_ids, \n",
    "        timestamps,\n",
    "        timestamp_buckets):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_timestamp = use_timestamp\n",
    "        self.unique_user_ids = unique_user_ids\n",
    "        self.timestamp_buckets = timestamp_buckets\n",
    "        self.timestamps = timestamps\n",
    "        \n",
    "        self.embed_user_id = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary = self.unique_user_ids,\n",
    "                mask_token = None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = len(self.unique_user_ids)+1,\n",
    "                output_dim = 32\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        if self.use_timestamp:\n",
    "            self.embed_timestamp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Discretization(\n",
    "                    bin_boundaries = list(self.timestamp_buckets)\n",
    "                ),\n",
    "\n",
    "                tf.keras.layers.Embedding(\n",
    "                    input_dim = len(list(self.timestamp_buckets))+1 ,\n",
    "                    output_dim = 32\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            self.normalize_timestamp = tf.keras.layers.Normalization(\n",
    "                axis = None #calcuate a scaler mean and variance \n",
    "            )\n",
    "            self.normalize_timestamp.adapt(self.timestamps)\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, timestamp = inputs\n",
    "\n",
    "        if self.use_timestamp:\n",
    "            user_id_embed = self.embed_user_id(user_id)\n",
    "            timestamp_embed = self.embed_timestamp(timestamp)\n",
    "            norm_timestamp = tf.reshape(self.normalize_timestamp(timestamp), (-1,1)) #(-1,1) means first dimension to be infered\n",
    "\n",
    "            return tf.concat([user_id_embed, timestamp_embed, norm_timestamp], axis = 1) #concatenate vertically\n",
    "            \n",
    "        return self.embed_user_id(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'S M B LEASING PLC'>,\\n 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Diversified Financials'>,\\n 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\\n 'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-696600287-VN/00'>,\\n 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>,\\n 'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'SEMB'>}\\n \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "{'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'S M B LEASING PLC'>,\n",
    " 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Diversified Financials'>,\n",
    " 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
    " 'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-696600287-VN/00'>,\n",
    " 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>,\n",
    " 'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'SEMB'>}\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this handles embedding item Identifiers and contextual data.\n",
    "movie title itself is used as the contexual information here.\n",
    "using timestamp is \n",
    "'''\n",
    "\n",
    "class ItemModel(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unique_item_ids,\n",
    "        unique_item_names,\n",
    "        unique_item_gics\n",
    "\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_tokens = 10000\n",
    "        self.unique_item_ids = unique_item_ids\n",
    "        self.unique_item_names = unique_item_names\n",
    "        self.unique_item_gics = unique_item_gics\n",
    "\n",
    "        self.embed_item_id = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary = self.unique_item_ids,\n",
    "                mask_token =None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = len(self.unique_item_ids)+1,\n",
    "                output_dim = 32\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.embed_items_gics = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary = unique_item_gics,\n",
    "                mask_token = None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = len(unique_item_gics)+1,\n",
    "                output_dim = len(unique_item_gics)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.textvectorizer = tf.keras.layers.TextVectorization(\n",
    "            max_tokens = self.max_tokens\n",
    "        )\n",
    "\n",
    "        self.embed_item_name = tf.keras.Sequential([\n",
    "            self.textvectorizer,\n",
    "\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim = self.max_tokens,\n",
    "                output_dim = 32,\n",
    "                mask_zero = True\n",
    "            ),\n",
    "\n",
    "            tf.keras.layers.GlobalAveragePooling1D() # reduces dimensionality to 1d (embedding layer embeddeds each word in a title one by one)\n",
    "        ])\n",
    "\n",
    "        self.textvectorizer.adapt(self.unique_item_names)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        item_id, item_name, item_gics = inputs\n",
    "\n",
    "        return tf.concat([\n",
    "            self.embed_item_id(item_id),\n",
    "            self.embed_item_name(item_name),\n",
    "            self.embed_items_gics(item_gics)\n",
    "        ],\n",
    "        axis = 1)\n",
    "        \n",
    "        # return self.embed_item_title(inputs['movie_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(\n",
    "\n",
    "    self,\n",
    "    use_timestamp,\n",
    "    unique_user_ids, \n",
    "    timestamps, \n",
    "    timestamp_buckets,\n",
    "    unique_item_ids,\n",
    "    unique_item_names,\n",
    "    unique_item_gics\n",
    "    ):\n",
    "    \n",
    "    super().__init__()\n",
    "\n",
    "    # embedding_dimension = 32\n",
    "    self.use_timestamp = use_timestamp\n",
    "    self.unique_user_ids = unique_user_ids \n",
    "    self.timestamps = timestamps\n",
    "    self.timestamp_buckets = timestamp_buckets\n",
    "    self.unique_item_ids = unique_item_ids\n",
    "    self.unique_item_names = unique_item_names\n",
    "    self.unique_item_gics = unique_item_gics\n",
    "\n",
    "    self.user_embeddings = UserModel(\n",
    "      use_timestamp = self.use_timestamp,\n",
    "      unique_user_ids = self.unique_user_ids, \n",
    "      timestamps = self.timestamps, \n",
    "      timestamp_buckets = self.timestamp_buckets\n",
    "      )\n",
    "\n",
    "    self.item_embeddings = ItemModel(\n",
    "      unique_item_ids = self.unique_item_ids,\n",
    "      unique_item_names = self.unique_item_names,\n",
    "      unique_item_gics = self.unique_item_gics\n",
    "      )\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, timestamp, item_id, item_name, item_gics = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings((user_id,timestamp))\n",
    "    item_embedding = self.item_embeddings((item_id, item_name, item_gics))\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, item_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_model = UserModel(\n",
    "    use_timestamp = True,\n",
    "    unique_user_ids = unique_user_ids, \n",
    "    timestamps = timestamps, \n",
    "    timestamp_buckets = timestamp_buckets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'SEMB'>,\n",
       " 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
       " 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Diversified Financials'>,\n",
       " 'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-696600287-VN/00'>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'S M B LEASING PLC'>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(portfolios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_model = ItemModel(\n",
    "    unique_item_ids = unique_item_ids,\n",
    "    unique_item_names = unique_item_names,\n",
    "    unique_item_gics = unique_item_gics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['SEMB']. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['S M B LEASING PLC']. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['Diversified Financials']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 97), dtype=float32, numpy=\n",
       "array([[ 4.3705329e-03, -2.2394991e-02, -3.5920691e-02, -2.1699822e-02,\n",
       "        -2.9262269e-02,  4.4337008e-02, -6.8609938e-03, -2.2273827e-02,\n",
       "        -1.1803556e-02, -1.7403759e-02,  3.2857466e-02, -4.0586103e-02,\n",
       "         3.7861932e-02, -1.7795421e-02, -4.2396702e-02, -7.9156756e-03,\n",
       "         3.2449391e-02, -2.6859224e-02, -4.7786739e-02, -2.9492307e-02,\n",
       "         3.7730385e-02, -5.2641630e-03,  2.5108252e-02, -2.3457885e-02,\n",
       "        -4.8597634e-02, -1.6620744e-02, -6.5700896e-03, -2.9219568e-02,\n",
       "        -8.4600076e-03,  3.0909069e-03, -3.2440647e-03, -4.2207129e-03,\n",
       "         1.3744962e-02,  7.0432923e-03,  1.6609214e-03, -1.9461032e-02,\n",
       "        -8.6226838e-04,  6.2110219e-03,  1.7358879e-02,  4.6559861e-03,\n",
       "         2.9412438e-03, -1.7536521e-02,  1.2989625e-02,  1.5450200e-02,\n",
       "         2.3383677e-02,  5.7675401e-03,  1.7021524e-02,  3.4264922e-03,\n",
       "        -1.2886984e-02,  1.6103169e-02,  1.1692495e-02, -1.0436247e-02,\n",
       "        -2.2977918e-02,  6.5817004e-03,  3.3208542e-02, -7.8698991e-05,\n",
       "         5.0128647e-03,  6.8991343e-03,  6.2706443e-03, -8.4223635e-03,\n",
       "        -1.7524188e-02,  5.3925640e-03, -1.1482561e-02,  1.9561136e-02,\n",
       "         4.7315549e-02, -4.5962241e-02, -2.6557196e-02,  2.0112846e-02,\n",
       "        -4.4295311e-02,  2.1355640e-02,  2.1105632e-03, -1.0894738e-02,\n",
       "        -4.8902642e-02,  2.8971422e-02, -4.6235096e-02,  3.6677431e-02,\n",
       "         1.8998910e-02,  2.7620804e-02,  2.8193619e-02, -1.4922630e-02,\n",
       "         2.1669496e-02, -4.6274818e-02,  7.3745362e-03, -1.1852492e-02,\n",
       "        -8.0813654e-03,  3.5133846e-03, -1.1986755e-02,  4.2968784e-02,\n",
       "        -1.1536919e-02,  1.6362261e-02,  3.8800884e-02, -4.5571614e-02,\n",
       "        -9.9221617e-04, -4.1407038e-02,  9.7782537e-04, -1.1107698e-03,\n",
       "        -4.4255462e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_user_model(([\"RPS-696600287-VN/00\"],[1643567400.0]))\n",
    "test_item_model((['SEMB'],['S M B LEASING PLC'],['Diversified Financials']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['RPS-696600287-VN/00']. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=[<tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>]. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['SEMB']. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['S M B LEASING PLC']. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=['Diversified Financials']. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.13506046]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranking_model = RankingModel(\n",
    "    use_timestamp = True,\n",
    "    unique_user_ids = unique_user_ids, \n",
    "    timestamps = timestamps, \n",
    "    timestamp_buckets = timestamp_buckets,\n",
    "    unique_item_ids = unique_item_ids,\n",
    "    unique_item_names = unique_item_names,\n",
    "    unique_item_gics = unique_item_gics\n",
    "    )\n",
    "\n",
    "test_ranking_model(([\"RPS-696600287-VN/00\"],[1643567400.0],['SEMB'],['S M B LEASING PLC'],['Diversified Financials']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    use_timestamp,\n",
    "    unique_user_ids, \n",
    "    timestamps, \n",
    "    timestamp_buckets,\n",
    "    unique_item_ids,\n",
    "    unique_item_names,\n",
    "    unique_item_gics\n",
    "    ):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    self.use_timestamp = use_timestamp\n",
    "    self.unique_user_ids = unique_user_ids \n",
    "    self.timestamps = timestamps\n",
    "    self.timestamp_buckets = timestamp_buckets\n",
    "    self.unique_item_ids = unique_item_ids\n",
    "    self.unique_item_names = unique_item_names\n",
    "    self.unique_item_gics = unique_item_gics\n",
    "\n",
    "    self.ranking_model: tf.keras.Model = RankingModel(\n",
    "      use_timestamp = self.use_timestamp,\n",
    "      unique_user_ids = self.unique_user_ids,\n",
    "      timestamps = self.timestamps,\n",
    "      timestamp_buckets = self.timestamp_buckets,\n",
    "      unique_item_ids = self.unique_item_ids,\n",
    "      unique_item_names = self.unique_item_names,\n",
    "      unique_item_gics = self.unique_item_gics\n",
    "      )\n",
    "\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"CDSACCNO\"],\n",
    "        features['UNIX_TS'],\n",
    "        features[\"STOCKCODE\"],\n",
    "        features[\"STOCKNAME\"],\n",
    "        features[\"GICS\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"RATING\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'SEMB'>,\n",
    " 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=5.0>,\n",
    " 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Diversified Financials'>,\n",
    " 'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-696600287-VN/00'>,\n",
    " 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1643567400.0>,\n",
    " 'STOCKNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(\n",
    "    use_timestamp = True,\n",
    "    unique_user_ids = unique_user_ids, \n",
    "    timestamps = timestamps, \n",
    "    timestamp_buckets = timestamp_buckets,\n",
    "    unique_item_ids = unique_item_ids,\n",
    "    unique_item_names = unique_item_names,\n",
    "    unique_item_gics = unique_item_gics\n",
    "    )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(10000).batch(128).cache()\n",
    "cached_test = test.batch(128).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - root_mean_squared_error: 1.4159 - loss: 2.0404 - regularization_loss: 0.0000e+00 - total_loss: 2.0404\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - root_mean_squared_error: 1.3309 - loss: 1.7798 - regularization_loss: 0.0000e+00 - total_loss: 1.7798\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.2256 - loss: 1.4192 - regularization_loss: 0.0000e+00 - total_loss: 1.4192\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.1498 - loss: 1.2364 - regularization_loss: 0.0000e+00 - total_loss: 1.2364\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.1015 - loss: 1.1308 - regularization_loss: 0.0000e+00 - total_loss: 1.1308\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.0694 - loss: 1.0659 - regularization_loss: 0.0000e+00 - total_loss: 1.0659\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.0432 - loss: 1.0167 - regularization_loss: 0.0000e+00 - total_loss: 1.0167\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.0220 - loss: 0.9826 - regularization_loss: 0.0000e+00 - total_loss: 0.9826\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.0068 - loss: 0.9700 - regularization_loss: 0.0000e+00 - total_loss: 0.9700\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 2ms/step - root_mean_squared_error: 0.9958 - loss: 0.9752 - regularization_loss: 0.0000e+00 - total_loss: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2151580fca0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - root_mean_squared_error: 1.5991 - loss: 1.9983 - regularization_loss: 0.0000e+00 - total_loss: 1.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.5991066694259644,\n",
       " 'loss': 0.31283149123191833,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.31283149123191833}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stock_info = pd.read_excel('../../data/stock_data.xlsx')\n",
    "stock_info = stock_info.drop(['Unnamed: 0'],axis = 1)\n",
    "stock_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>buisnesssummary</th>\n",
       "      <th>gics_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HBS</td>\n",
       "      <td>hSenid Business Solutions PLC</td>\n",
       "      <td>An indigenous multinational catering towards m...</td>\n",
       "      <td>45103010 - Application Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TYRE</td>\n",
       "      <td>KELANI TYRES PLC</td>\n",
       "      <td>Manufacturing tyres and tubes and marketing lo...</td>\n",
       "      <td>Automobiles &amp; Components</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL</td>\n",
       "      <td>AMANA BANK PLC</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFCC</td>\n",
       "      <td>DFCC BANK PLC</td>\n",
       "      <td>The principal activities of DFCC Bank include ...</td>\n",
       "      <td>Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMB</td>\n",
       "      <td>COMMERCIAL BANK OF CEYLON PLC</td>\n",
       "      <td>Commercial Banking</td>\n",
       "      <td>Banks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                           name  \\\n",
       "0    HBS  hSenid Business Solutions PLC   \n",
       "1   TYRE               KELANI TYRES PLC   \n",
       "2    ABL                 AMANA BANK PLC   \n",
       "3   DFCC                  DFCC BANK PLC   \n",
       "4   COMB  COMMERCIAL BANK OF CEYLON PLC   \n",
       "\n",
       "                                     buisnesssummary  \\\n",
       "0  An indigenous multinational catering towards m...   \n",
       "1  Manufacturing tyres and tubes and marketing lo...   \n",
       "2                                            unknown   \n",
       "3  The principal activities of DFCC Bank include ...   \n",
       "4                                 Commercial Banking   \n",
       "\n",
       "                         gics_code  \n",
       "0  45103010 - Application Software  \n",
       "1         Automobiles & Components  \n",
       "2                            Banks  \n",
       "3                            Banks  \n",
       "4                            Banks  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "symb_to_name = dict(zip(stock_info.symbol,stock_info.name))\n",
    "symb_to_gics = dict(zip(stock_info.symbol, stock_info.gics_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "SINS: [[0.6293522]]\n"
     ]
    }
   ],
   "source": [
    "test_ratings = {}\n",
    "test_item_ids = [\"SINS\"] #, \"KZOO\", \"LOFC\",\"DIST\"\n",
    "for item_id in test_item_ids:\n",
    "  test_ratings[item_id] = model({\n",
    "      \"CDSACCNO\": np.array([\"RPS-797423181-VN/00\"]),\n",
    "      \"UNIX_TS\": np.array([1664821800.0]),\n",
    "      \"STOCKCODE\": np.array([item_id]),\n",
    "      \"STOCKNAME\":np.array([symb_to_name.get(item_id)]),\n",
    "      \"GICS\":np.array([symb_to_gics.get(item_id)])\n",
    "  })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'STOCKCODE': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'SINS'], dtype=object)>,\n",
       " 'RATING': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       " 'GICS': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Retailing'], dtype=object)>,\n",
       " 'CDSACCNO': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'RPS-797423181-VN/00'], dtype=object)>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.6648218e+09], dtype=float32)>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'SINGER (SRI LANKA) PLC'], dtype=object)>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test.batch(1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
