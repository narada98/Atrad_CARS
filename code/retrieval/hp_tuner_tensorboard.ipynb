{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear any logs from previous runs\n",
    "# rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from recommender import Recommender\n",
    "from user_embedding import UserModel\n",
    "from item_embedding import ItemModel\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = r'D:\\dev work\\recommender systems\\ATRAD_CARS'\n",
    "\n",
    "train_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/train\").cache() #data\\ratings_train\n",
    "test_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/test\").cache()\n",
    "portfolios = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_tfds\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\naradaw\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "model = Recommender(\n",
    "    use_timestamp = True,\n",
    "    portfolios = portfolios\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.3))\n",
    "\n",
    "train_ds = train_ds.shuffle(1000).batch(128) #.cache()\n",
    "test_ds = test_ds.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = os.path.join(base_loc ,\"logs/fit/retriever_opt/\" + \"retriever\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(base_loc ,\"logs/fit/retriever_opt/\" + \"retriever\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "    histogram_freq=0,\n",
    "    embeddings_freq = 1,\n",
    "    write_images = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25/25 [==============================] - 9s 214ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0029 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0042 - factorized_top_k/top_50_categorical_accuracy: 0.0140 - factorized_top_k/top_100_categorical_accuracy: 0.0299 - loss: 575.2949 - regularization_loss: 0.0000e+00 - total_loss: 575.2949 - val_factorized_top_k/top_1_categorical_accuracy: 0.0104 - val_factorized_top_k/top_5_categorical_accuracy: 0.0117 - val_factorized_top_k/top_10_categorical_accuracy: 0.0156 - val_factorized_top_k/top_50_categorical_accuracy: 0.0338 - val_factorized_top_k/top_100_categorical_accuracy: 0.0533 - val_loss: 0.0000e+00 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 5s 182ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0062 - factorized_top_k/top_50_categorical_accuracy: 0.0520 - factorized_top_k/top_100_categorical_accuracy: 0.1014 - loss: 533.2698 - regularization_loss: 0.0000e+00 - total_loss: 533.2698 - val_factorized_top_k/top_1_categorical_accuracy: 0.0156 - val_factorized_top_k/top_5_categorical_accuracy: 0.0169 - val_factorized_top_k/top_10_categorical_accuracy: 0.0182 - val_factorized_top_k/top_50_categorical_accuracy: 0.0390 - val_factorized_top_k/top_100_categorical_accuracy: 0.0689 - val_loss: 0.0000e+00 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 5s 189ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0049 - factorized_top_k/top_5_categorical_accuracy: 0.0088 - factorized_top_k/top_10_categorical_accuracy: 0.0169 - factorized_top_k/top_50_categorical_accuracy: 0.1254 - factorized_top_k/top_100_categorical_accuracy: 0.2288 - loss: 466.1678 - regularization_loss: 0.0000e+00 - total_loss: 466.1678 - val_factorized_top_k/top_1_categorical_accuracy: 0.0195 - val_factorized_top_k/top_5_categorical_accuracy: 0.0195 - val_factorized_top_k/top_10_categorical_accuracy: 0.0208 - val_factorized_top_k/top_50_categorical_accuracy: 0.0416 - val_factorized_top_k/top_100_categorical_accuracy: 0.0715 - val_loss: 0.0000e+00 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0000e+00\n",
      "dict_keys(['factorized_top_k/top_1_categorical_accuracy', 'factorized_top_k/top_5_categorical_accuracy', 'factorized_top_k/top_10_categorical_accuracy', 'factorized_top_k/top_50_categorical_accuracy', 'factorized_top_k/top_100_categorical_accuracy', 'loss', 'regularization_loss', 'total_loss', 'val_factorized_top_k/top_1_categorical_accuracy', 'val_factorized_top_k/top_5_categorical_accuracy', 'val_factorized_top_k/top_10_categorical_accuracy', 'val_factorized_top_k/top_50_categorical_accuracy', 'val_factorized_top_k/top_100_categorical_accuracy', 'val_loss', 'val_regularization_loss', 'val_total_loss'])\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=3, \n",
    "    verbose = 1,\n",
    "    validation_data=test_ds,\n",
    "    validation_freq=1,\n",
    "    callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 137ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0195 - factorized_top_k/top_5_categorical_accuracy: 0.0195 - factorized_top_k/top_10_categorical_accuracy: 0.0208 - factorized_top_k/top_50_categorical_accuracy: 0.0416 - factorized_top_k/top_100_categorical_accuracy: 0.0715 - loss: 504.5273 - regularization_loss: 0.0000e+00 - total_loss: 504.5273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.019505850970745087,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.019505850970745087,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.020806241780519485,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.04161248356103897,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.07152145355939865,\n",
       " 'loss': 0.0,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.evaluate(test_ds, return_dict=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020806241780519485"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['factorized_top_k/top_10_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(base_loc ,\"logs/retriever_opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "hp_doc_path = os.path.join(log_dir, 'hparam_tuning')\n",
    "with tf.summary.create_file_writer(hp_doc_path).as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_OPTIMIZER],\n",
    "    metrics=[\n",
    "        hp.Metric('factorized_top_k/top_10_categorical_accuracy',\n",
    "        display_name='factorized_top_k/top_10_categorical_accuracy')\n",
    "        ],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    top_10_categorical_accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar('factorized_top_k/top_10_categorical_accuracy', top_10_categorical_accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = Recommender(\n",
    "    use_timestamp = True,\n",
    "    portfolios = portfolios\n",
    "    )\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER]\n",
    "  )\n",
    "\n",
    "  # model.fit(x_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "\n",
    "  model.fit(\n",
    "    train_ds, \n",
    "    epochs=1, \n",
    "    verbose = 1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(log_dir),  # log metrics\n",
    "        hp.KerasCallback(log_dir, hparams),  # log hparams\n",
    "    ],\n",
    "    )\n",
    "  \n",
    "  res = model.evaluate(test_ds, return_dict= True)\n",
    "  # print(res)\n",
    "  return res['factorized_top_k/top_10_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'optimizer': 'adam'}\n",
      "25/25 [==============================] - 5s 140ms/step - factorized_top_k/top_1_categorical_accuracy: 3.2499e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0016 - factorized_top_k/top_50_categorical_accuracy: 0.0123 - factorized_top_k/top_100_categorical_accuracy: 0.0227 - loss: 573.7569 - regularization_loss: 0.0000e+00 - total_loss: 573.7569\n",
      "7/7 [==============================] - 2s 134ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0026 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0065 - factorized_top_k/top_50_categorical_accuracy: 0.0221 - factorized_top_k/top_100_categorical_accuracy: 0.0377 - loss: 465.5673 - regularization_loss: 0.0000e+00 - total_loss: 465.5673\n",
      "--- Starting trial: run-1\n",
      "{'optimizer': 'sgd'}\n",
      "25/25 [==============================] - 5s 136ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0185 - factorized_top_k/top_5_categorical_accuracy: 0.0185 - factorized_top_k/top_10_categorical_accuracy: 0.0192 - factorized_top_k/top_50_categorical_accuracy: 0.0208 - factorized_top_k/top_100_categorical_accuracy: 0.0312 - loss: 572.7763 - regularization_loss: 0.0000e+00 - total_loss: 572.7763\n",
      "7/7 [==============================] - 1s 132ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0169 - factorized_top_k/top_5_categorical_accuracy: 0.0169 - factorized_top_k/top_10_categorical_accuracy: 0.0169 - factorized_top_k/top_50_categorical_accuracy: 0.0208 - factorized_top_k/top_100_categorical_accuracy: 0.0351 - loss: 465.1744 - regularization_loss: 0.0000e+00 - total_loss: 465.1744\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for optimizer in HP_OPTIMIZER.domain.values:\n",
    "    hparams = {\n",
    "        HP_OPTIMIZER: optimizer,\n",
    "    }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run(os.path.join(hp_doc_path, run_name), hparams)\n",
    "    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\\hparam_tuning\n",
    "# %tensorboard --logdir logs\\fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atrad_cars_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
