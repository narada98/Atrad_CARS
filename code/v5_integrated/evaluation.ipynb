{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import array\n",
    "import collections\n",
    "\n",
    "from typing import Dict, List, Optional, Text, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_06_07_22\\retriever_port_v2_hoo\" #r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\retriever_port_v2\"\n",
    "ranking_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\tf_listwise_ranking_2024_05_27_11_20\"\n",
    "stock_info_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\stock_data.xlsx\"\n",
    "\n",
    "test_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_hoo_test\"\n",
    "train_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_hoo_train\"\n",
    "\n",
    "portfolios_loc = r\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_v2/portfolios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_06_11_34\\retriever_port_v2\" #r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\retriever_port_v2\"\n",
    "# ranking_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\tf_listwise_ranking_2024_05_27_11_20\"\n",
    "# stock_info_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\stock_data.xlsx\"\n",
    "\n",
    "# test_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_test\"\n",
    "# train_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_train\"\n",
    "\n",
    "# portfolios_loc = r\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_v2/portfolios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.load(test_ds_loc).cache()\n",
    "\n",
    "train_ds = tf.data.Dataset.load(train_ds_loc).cache()\n",
    "\n",
    "train_ds_1 = train_ds.batch(len(train_ds))\n",
    "test_ds_1 = test_ds.batch(len(test_ds))\n",
    "\n",
    "portfolios = tf.data.Dataset.load(portfolios_loc).cache()\n",
    "\n",
    "items_ids = portfolios.batch(10000).map(lambda x: x[\"STOCKCODE\"])\n",
    "item_names = portfolios.batch(10000).map(lambda x: x[\"STOCKNAME\"])\n",
    "item_GICS = portfolios.batch(10000).map(lambda x: x[\"GICS\"])\n",
    "\n",
    "user_ids = portfolios.batch(10000).map(lambda x: x[\"CDSACCNO\"])\n",
    "\n",
    "unique_item_ids = np.unique(np.concatenate(list(items_ids)))\n",
    "unique_item_names = np.unique(np.concatenate(list(item_names)))\n",
    "unique_item_gics = np.unique(np.concatenate(list(item_GICS)))\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# need these to initialize timestamp embedding layers in future steps\n",
    "\n",
    "timestamps = np.concatenate(list(portfolios.map(lambda x: x[\"UNIX_TS\"]).batch(100)))\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval_recommender_v2 import Retriever\n",
    "\n",
    "retriever = Retriever(\n",
    "    use_timestamp = True,\n",
    "    portfolios = portfolios\n",
    ")\n",
    "\n",
    "retriever.load_weights(retriever_location_)\n",
    "\n",
    "retriever.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranker_recommender import Ranker\n",
    "\n",
    "ranker = Ranker(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    portfolios = portfolios\n",
    ")\n",
    "\n",
    "ranker.load_weights(ranking_location_)\n",
    "ranker.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items data shape :: (280, 3)\n"
     ]
    }
   ],
   "source": [
    "stock_info = pd.read_excel(stock_info_loc)\n",
    "stock_info = stock_info.drop(['Unnamed: 0','buisnesssummary'],axis = 1)\n",
    "stock_info = stock_info.rename(columns = {\n",
    "    'symbol':'STOCKCODE',\n",
    "    'name' : 'STOCKNAME',\n",
    "    'gics_code' : 'GICS'\n",
    "})\n",
    "stock_info = stock_info[~stock_info['GICS'].isna()]\n",
    "\n",
    "stock_info.shape\n",
    "print(\"items data shape :: {}\".format(stock_info.shape))\n",
    "unique_items_ = np.unique(np.concatenate(list(train_ds.batch(1000).map(lambda x: x[\"STOCKCODE\"]).as_numpy_iterator())))\n",
    "stock_info = stock_info[stock_info['STOCKCODE'].isin([item.decode('utf-8') for item in unique_items_])]\n",
    "\n",
    "items_ds = tf.data.Dataset.from_tensor_slices(stock_info.to_dict(orient= 'list'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(retriever,\n",
    "             test: tf.data.Dataset,\n",
    "             train: Optional[tf.data.Dataset] = None,\n",
    "             timestamp: int = datetime.timestamp(datetime.now()),\n",
    "             k: int = 10):\n",
    "  \n",
    "  item_ids = np.concatenate(list(items_ds.batch(1000).map(lambda x: x[\"STOCKCODE\"]).as_numpy_iterator()))\n",
    "\n",
    "  item_vocabulary = dict(zip(item_ids.tolist(), range(len(item_ids))))\n",
    "  item_vocabulary_inv = {v: k for k, v in item_vocabulary.items()}\n",
    "\n",
    "  train_user_to_items = collections.defaultdict(lambda: array.array(\"i\"))\n",
    "  test_user_to_items = collections.defaultdict(lambda: array.array(\"i\"))\n",
    "\n",
    "  if train is not None:\n",
    "    for row in train.as_numpy_iterator():\n",
    "      user_id = row[\"CDSACCNO\"]\n",
    "      item_id = item_vocabulary[row[\"STOCKCODE\"]]\n",
    "      train_user_to_items[user_id].append(item_id)\n",
    "\n",
    "  for row in test.as_numpy_iterator():\n",
    "    user_id = row[\"CDSACCNO\"]\n",
    "    item_id = item_vocabulary[row[\"STOCKCODE\"]]\n",
    "    test_user_to_items[user_id].append(item_id)\n",
    "\n",
    "  item_embeddings = np.concatenate(list(items_ds.batch(len(items_ds)).map(lambda x: retriever.item_model(x)).as_numpy_iterator()))\n",
    "\n",
    "  user_ids = []\n",
    "  precision_values = []\n",
    "  recall_values = []\n",
    "  num_test_items = []\n",
    "  num_train_items = []\n",
    "  recommendations = []\n",
    "\n",
    "  for user_id, test_items in tqdm(test_user_to_items.items()):\n",
    "    user_embedding = retriever.user_model(\n",
    "      {\n",
    "        'CDSACCNO' : tf.constant([user_id]),\n",
    "        'UNIX_TS' : tf.constant([timestamp])\n",
    "      }\n",
    "      ).numpy()\n",
    "    scores = (user_embedding @ item_embeddings.T).flatten()\n",
    "\n",
    "    test_items = np.frombuffer(test_items, dtype=np.int32)\n",
    "    \n",
    "    if train is not None:\n",
    "      train_items = np.frombuffer(\n",
    "          train_user_to_items[user_id], dtype=np.int32)\n",
    "      scores[train_items] = -1e6\n",
    "\n",
    "    \n",
    "\n",
    "    top_items = np.argsort(-scores)[:k]\n",
    "    recommendations.append([item_vocabulary_inv[item_id].decode('utf-8') for item_id in top_items])\n",
    "\n",
    "    num_test_items_in_k = sum(x in top_items for x in  test_items)\n",
    "    precision_values.append(num_test_items_in_k / k)\n",
    "    \n",
    "    recall_values.append(num_test_items_in_k / len(test_items))\n",
    "    num_test_items.append(len((test_items)))\n",
    "    num_train_items.append(len(train_user_to_items[user_id]))\n",
    "    user_ids.append(user_id)\n",
    "\n",
    "  results_df_ = pd.DataFrame(\n",
    "    columns = ['CDSACCNO','precision@k', 'recall@k','num_test_items','portfolio_size', 'recommendations'],\n",
    "    data = list(zip(user_ids, precision_values, recall_values, num_test_items, num_train_items, recommendations))\n",
    "  )\n",
    "\n",
    "  return {\n",
    "      \"precision_at_k\": np.mean(precision_values),\n",
    "      \"recall_at_k\": np.mean(recall_values),\n",
    "      \"results_df_\" : results_df_\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5906/5906 [00:19<00:00, 305.46it/s]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(\n",
    "    retriever,\n",
    "    test_ds,\n",
    "    train_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05374195733152726, 0.12099826568855412)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['precision_at_k'] , results['recall_at_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDSACCNO</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>num_test_items</th>\n",
       "      <th>portfolio_size</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDF-74565-LI/00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[SCAP, SEMB, CALT, CSF, LOLC, SLTL, COCR, ASPH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMS-800262640-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>[PLR, CINV, UAL, CALT, MARA, SEMB, ALLI, GRAN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COM-69742-LC/00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>[AHPL, CFIN, GUAR, CINS, RENU, CHMX, WAPO, LMF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMS-861802000-VN/00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>[HPFL, CARS, NEST, SHAL, CERA, CHL, AFS, BFL, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDF-743463188-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[ACAP, CALF, AMF, ATL, MFL, UBC, ACME, MEL, BF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>BMS-68660-LI/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[LCBF, AMF, BFN, MFL, WAPO, ACAP, PMB, MBSL, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>BMS-683600342-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[GUAR, COMD, CARG, SEYB, BUKI, CARS, AHUN, TAF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>CAS-86452-LI/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>[ABAN, LMF, SOY, GUAR, CINS, LVEN, RENU, UAL, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>CMB-5826-LC/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[SAMP, HASU, COMB, DFCC, HAYL, DIAL, NTB, CFIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>BMS-67319-LI/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>[MARA, KZOO, LCBF, RIL, TESS, MEL, ASIY, REEF,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CDSACCNO  precision@k  recall@k  num_test_items  \\\n",
       "0         HDF-74565-LI/00          0.1  0.500000               2   \n",
       "1     BMS-800262640-VN/00          0.0  0.000000               2   \n",
       "2         COM-69742-LC/00          0.1  0.100000              10   \n",
       "3     BMS-861802000-VN/00          0.1  0.071429              14   \n",
       "4     HDF-743463188-VN/00          0.0  0.000000               2   \n",
       "...                   ...          ...       ...             ...   \n",
       "5901      BMS-68660-LI/00          0.0  0.000000               3   \n",
       "5902  BMS-683600342-VN/00          0.0  0.000000               3   \n",
       "5903      CAS-86452-LI/00          0.0  0.000000               3   \n",
       "5904       CMB-5826-LC/00          0.0  0.000000               2   \n",
       "5905      BMS-67319-LI/00          0.0  0.000000               4   \n",
       "\n",
       "      portfolio_size                                    recommendations  \n",
       "0                  9  [SCAP, SEMB, CALT, CSF, LOLC, SLTL, COCR, ASPH...  \n",
       "1                 10  [PLR, CINV, UAL, CALT, MARA, SEMB, ALLI, GRAN,...  \n",
       "2                 38  [AHPL, CFIN, GUAR, CINS, RENU, CHMX, WAPO, LMF...  \n",
       "3                 58  [HPFL, CARS, NEST, SHAL, CERA, CHL, AFS, BFL, ...  \n",
       "4                  9  [ACAP, CALF, AMF, ATL, MFL, UBC, ACME, MEL, BF...  \n",
       "...              ...                                                ...  \n",
       "5901              10  [LCBF, AMF, BFN, MFL, WAPO, ACAP, PMB, MBSL, C...  \n",
       "5902              10  [GUAR, COMD, CARG, SEYB, BUKI, CARS, AHUN, TAF...  \n",
       "5903              10  [ABAN, LMF, SOY, GUAR, CINS, LVEN, RENU, UAL, ...  \n",
       "5904               8  [SAMP, HASU, COMB, DFCC, HAYL, DIAL, NTB, CFIN...  \n",
       "5905              18  [MARA, KZOO, LCBF, RIL, TESS, MEL, ASIY, REEF,...  \n",
       "\n",
       "[5906 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['results_df_']['CDSACCNO'] = results['results_df_']['CDSACCNO'].apply(lambda x: x.decode('utf-8'))\n",
    "results['results_df_']\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loc_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\results\"\n",
    "\n",
    "retriever_name = os.path.basename(retriever_location_)\n",
    "ranker_name = os.path.basename(ranking_location_)\n",
    "\n",
    "results_file_name = retriever_name + \"_&_\" + ranker_name + \"_results_hoo.csv\"\n",
    "\n",
    "results_save_path = os.path.join(results_loc_, results_file_name)\n",
    "# results_save_path\n",
    "results['results_df_'].to_csv(results_save_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atrad_cars_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
