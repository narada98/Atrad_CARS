{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_06_07_22\\retriever_port_v2_hoo\" #r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\retriever_port_v2\"\n",
    "ranking_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\tf_listwise_ranking_2024_05_27_11_20\"\n",
    "stock_info_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\stock_data.xlsx\"\n",
    "\n",
    "test_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_hoo_test\"\n",
    "train_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_hoo_train\"\n",
    "\n",
    "portfolios_loc = r\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_v2/portfolios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_06_10_15\\retriever_port_v2\" #r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\retriever_port_v2\"\n",
    "ranking_location_ = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\model_weights\\2024_05_27\\tf_listwise_ranking_2024_05_27_11_20\"\n",
    "stock_info_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\stock_data.xlsx\"\n",
    "\n",
    "test_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_test\"\n",
    "train_ds_loc = r\"D:\\dev work\\recommender systems\\Atrad_CARS\\data\\portfolios_v2\\retriver_train\"\n",
    "\n",
    "portfolios_loc = r\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_v2/portfolios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.load(test_ds_loc).cache()\n",
    "\n",
    "train_ds = tf.data.Dataset.load(train_ds_loc).cache()\n",
    "\n",
    "train_ds_1 = train_ds.batch(len(train_ds))\n",
    "test_ds_1 = test_ds.batch(len(test_ds))\n",
    "\n",
    "portfolios = tf.data.Dataset.load(portfolios_loc).cache()\n",
    "\n",
    "items_ids = portfolios.batch(10000).map(lambda x: x[\"STOCKCODE\"])\n",
    "item_names = portfolios.batch(10000).map(lambda x: x[\"STOCKNAME\"])\n",
    "item_GICS = portfolios.batch(10000).map(lambda x: x[\"GICS\"])\n",
    "\n",
    "user_ids = portfolios.batch(10000).map(lambda x: x[\"CDSACCNO\"])\n",
    "\n",
    "unique_item_ids = np.unique(np.concatenate(list(items_ids)))\n",
    "unique_item_names = np.unique(np.concatenate(list(item_names)))\n",
    "unique_item_gics = np.unique(np.concatenate(list(item_GICS)))\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# need these to initialize timestamp embedding layers in future steps\n",
    "\n",
    "timestamps = np.concatenate(list(portfolios.map(lambda x: x[\"UNIX_TS\"]).batch(100)))\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_dict = next(iter(train_ds_1))\n",
    "test_ds_dict = next(iter(test_ds_1))\n",
    "#test\n",
    "data_dict = {\n",
    "    'CDSACCNO': test_ds_dict['CDSACCNO'].numpy(),\n",
    "    'STOCKCODE': test_ds_dict['STOCKCODE'].numpy(),\n",
    "    'STOCKNAME': test_ds_dict['STOCKNAME'].numpy(),\n",
    "    'GICS': test_ds_dict['GICS'].numpy(),\n",
    "    'UNIX_TS': test_ds_dict['UNIX_TS'].numpy(),\n",
    "    'RATING': test_ds_dict['RATING'].numpy(),\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "test_df = test_df.astype(\n",
    "    {\n",
    "        'CDSACCNO' : 'str',\n",
    "        'STOCKCODE' : 'str',\n",
    "        'STOCKNAME' : 'str',\n",
    "        'GICS' : 'str'\n",
    "        })\n",
    "\n",
    "#train\n",
    "data_dict = {\n",
    "    'CDSACCNO': train_ds_dict['CDSACCNO'].numpy(),\n",
    "    'STOCKCODE': train_ds_dict['STOCKCODE'].numpy(),\n",
    "    'STOCKNAME': train_ds_dict['STOCKNAME'].numpy(),\n",
    "    'GICS': train_ds_dict['GICS'].numpy(),\n",
    "    'UNIX_TS': train_ds_dict['UNIX_TS'].numpy(),\n",
    "    'RATING': train_ds_dict['RATING'].numpy(),\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(data_dict)\n",
    "\n",
    "train_df = train_df.astype(\n",
    "    {\n",
    "        'CDSACCNO' : 'str',\n",
    "        'STOCKCODE' : 'str',\n",
    "        'STOCKNAME' : 'str',\n",
    "        'GICS' : 'str'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval_recommender import Retriever\n",
    "\n",
    "retriever = Retriever(\n",
    "    use_timestamp = True,\n",
    "    portfolios = portfolios\n",
    ")\n",
    "\n",
    "retriever.load_weights(retriever_location_)\n",
    "\n",
    "retriever.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranker_recommender import Ranker\n",
    "\n",
    "ranker = Ranker(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    portfolios = portfolios\n",
    ")\n",
    "\n",
    "ranker.load_weights(ranking_location_)\n",
    "ranker.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items data shape :: (280, 3)\n"
     ]
    }
   ],
   "source": [
    "stock_info = pd.read_excel(stock_info_loc)\n",
    "stock_info = stock_info.drop(['Unnamed: 0','buisnesssummary'],axis = 1)\n",
    "stock_info = stock_info.rename(columns = {\n",
    "    'symbol':'STOCKCODE',\n",
    "    'name' : 'STOCKNAME',\n",
    "    'gics_code' : 'GICS'\n",
    "})\n",
    "stock_info = stock_info[~stock_info['GICS'].isna()]\n",
    "\n",
    "stock_info.shape\n",
    "print(\"items data shape :: {}\".format(stock_info.shape))\n",
    "\n",
    "items_ds = tf.data.Dataset.from_tensor_slices(stock_info.to_dict(orient= 'list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2name = dict(zip(stock_info.STOCKCODE, stock_info.STOCKNAME))\n",
    "code2gics = dict(zip(stock_info.STOCKCODE, stock_info.GICS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete recommender function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([280])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_identiifiers = items_ds.map(lambda x: x[\"STOCKCODE\"])\n",
    "items_identiifiers = next(iter(items_identiifiers.batch(len(items_identiifiers))))\n",
    "items_identiifiers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x2789ab3e6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(\n",
    "    query_model = retriever.user_model,\n",
    "    k = 10)\n",
    "    \n",
    "retriever_item_model = retriever.item_model\n",
    "mapped_items = items_ds.batch(len(items_ds)).map(lambda x : retriever_item_model(x, map_ = True))\n",
    "\n",
    "mapped_items_tensor = next(iter(mapped_items))\n",
    "index.index(mapped_items_tensor, items_identiifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_ = test_df.groupby('CDSACCNO')\n",
    "train_users_ = train_df.groupby('CDSACCNO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_(CDSACCNO, timestamp = 1664821800.0):\n",
    "\n",
    "    seen_items = train_df.loc[train_df.CDSACCNO == CDSACCNO].STOCKCODE.values.reshape(1, -1)\n",
    "\n",
    "    \n",
    "    _, recommendations = index.query_with_exclusions(\n",
    "    queries = (\n",
    "        tf.constant([CDSACCNO]),\n",
    "        tf.constant([timestamp])\n",
    "        ),\n",
    "    exclusions = seen_items\n",
    "    )\n",
    "\n",
    "    recommendations = [reco.decode('utf-8') for reco in recommendations.numpy().flatten()]\n",
    "    # print(f\"Recommendations for user %s: {recommendations}\" %(test_user))\n",
    "\n",
    "    names = np.array([code2name[code] for code in recommendations])\n",
    "    gics = np.array([code2gics[code] for code in recommendations])\n",
    "\n",
    "    user = {\n",
    "    'CDSACCNO' : np.array([CDSACCNO]),\n",
    "    'STOCKCODE' : np.array(recommendations).reshape(-1,10),\n",
    "    'GICS' : gics.reshape(-1,10),\n",
    "    'STOCKNAME' : names.reshape(-1,10)\n",
    "    }\n",
    "\n",
    "    pred_ratings = ranker(user)\n",
    "\n",
    "    recommendations_w_ratings = pd.DataFrame()\n",
    "    recommendations_w_ratings['STOCKCODE'] = recommendations\n",
    "    recommendations_w_ratings['PRED_RATING'] = pred_ratings.numpy().flatten()\n",
    "    recommendations_w_ratings = recommendations_w_ratings.sort_values( by = ['PRED_RATING'], ascending= False).reset_index(drop = True)\n",
    "\n",
    "    user_test_port_ = test_df.iloc[test_users_.groups[CDSACCNO]].sort_values('RATING', ascending = False)\n",
    "    recommendations_w_ratings = recommendations_w_ratings.join(user_test_port_.set_index('STOCKCODE'), on = 'STOCKCODE')[['STOCKCODE','PRED_RATING','RATING']]\n",
    "    \n",
    "    hit_perc = (10 - recommendations_w_ratings['RATING'].isna().sum())/len(recommendations_w_ratings)\n",
    "\n",
    "    return recommendations_w_ratings, hit_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5906 [00:00<?, ?it/s]C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_8264\\2312754527.py:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_ = pd.concat(\n",
      "  0%|          | 6/5906 [00:04<31:27,  3.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TopK.query_with_exclusions at 0x00000276AE59FF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/5906 [00:04<28:13,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function TopK.query_with_exclusions at 0x00000276AE59FF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5906/5906 [05:46<00:00, 17.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "292.1999999999977"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_timestamp = datetime.timestamp(datetime.now())\n",
    "\n",
    "total_hit_perc_ = 0\n",
    "results_ = pd.DataFrame(columns = ['CDSACCNO','hit_perc'])\n",
    "\n",
    "for user in tqdm(test_df.CDSACCNO.unique()):\n",
    "    _, hit_perc_ = recommend_(user, test_timestamp)\n",
    "    results_ = pd.concat(\n",
    "        [\n",
    "            results_,\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                'CDSACCNO':user,\n",
    "                'hit_perc':hit_perc_\n",
    "                }\n",
    "            ])\n",
    "        ], ignore_index = True)\n",
    "    total_hit_perc_ += hit_perc_\n",
    "\n",
    "# (total_hit_perc_/test_df.CDSACCNO.nunique())*100\n",
    "total_hit_perc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.947511005756819"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_hit_perc_/test_df.CDSACCNO.nunique())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDSACCNO</th>\n",
       "      <th>hit_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDF-74565-LI/00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMS-800262640-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COM-69742-LC/00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMS-861802000-VN/00</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDF-743463188-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>BMS-68660-LI/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>BMS-683600342-VN/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>CAS-86452-LI/00</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>CMB-5826-LC/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>BMS-67319-LI/00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CDSACCNO  hit_perc\n",
       "0         HDF-74565-LI/00       0.1\n",
       "1     BMS-800262640-VN/00       0.0\n",
       "2         COM-69742-LC/00       0.1\n",
       "3     BMS-861802000-VN/00       0.3\n",
       "4     HDF-743463188-VN/00       0.0\n",
       "...                   ...       ...\n",
       "5901      BMS-68660-LI/00       0.0\n",
       "5902  BMS-683600342-VN/00       0.0\n",
       "5903      CAS-86452-LI/00       0.1\n",
       "5904       CMB-5826-LC/00       0.0\n",
       "5905      BMS-67319-LI/00       0.0\n",
       "\n",
       "[5906 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hit_perc\n",
       "0.0    3653\n",
       "0.1    1724\n",
       "0.2     426\n",
       "0.3      79\n",
       "0.4      17\n",
       "0.5       4\n",
       "0.7       1\n",
       "0.8       1\n",
       "0.6       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_.hit_perc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df_ = pd.DataFrame()\n",
    "\n",
    "# results_df_['hit_perc'] = results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall @k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import collections\n",
    "\n",
    "from typing import Dict, List, Optional, Text, Tuple\n",
    "\n",
    "def evaluate(retriever,\n",
    "             test: tf.data.Dataset,\n",
    "             train: Optional[tf.data.Dataset] = None,\n",
    "             timestamp: int = datetime.timestamp(datetime.now()),\n",
    "             k: int = 10) -> Dict[Text, float]:\n",
    "\n",
    "  item_ids = stock_info['STOCKCODE'].unique()\n",
    "  \n",
    "  item_ids = np.concatenate(\n",
    "      list(items_ds.batch(1000).map(lambda x: x[\"STOCKCODE\"]).as_numpy_iterator()))\n",
    "\n",
    "  item_vocabulary = dict(zip(item_ids.tolist(), range(len(item_ids))))\n",
    "\n",
    "  train_user_to_items = collections.defaultdict(lambda: array.array(\"i\"))\n",
    "  test_user_to_items = collections.defaultdict(lambda: array.array(\"i\"))\n",
    "\n",
    "  if train is not None:\n",
    "    for row in train.as_numpy_iterator():\n",
    "      user_id = row[\"CDSACCNO\"]\n",
    "      item_id = item_vocabulary[row[\"STOCKCODE\"]]\n",
    "      train_user_to_items[user_id].append(item_id)\n",
    "\n",
    "  for row in test.as_numpy_iterator():\n",
    "    user_id = row[\"CDSACCNO\"]\n",
    "    item_id = item_vocabulary[row[\"STOCKCODE\"]]\n",
    "    test_user_to_items[user_id].append(item_id)\n",
    "\n",
    "  item_embeddings = mapped_items_tensor.numpy()\n",
    "\n",
    "  user_ids = []\n",
    "  precision_values = []\n",
    "  recall_values = []\n",
    "  num_test_items = []\n",
    "  num_train_items = []\n",
    "\n",
    "  for user_id, test_items in tqdm(test_user_to_items.items()):\n",
    "    user_embedding = retriever.user_model(\n",
    "      (\n",
    "        tf.constant([user_id]),\n",
    "        tf.constant([timestamp])\n",
    "       )\n",
    "      ).numpy()\n",
    "    scores = (user_embedding @ item_embeddings.T).flatten()\n",
    "\n",
    "    test_items = np.frombuffer(test_items, dtype=np.int32)\n",
    "    \n",
    "    if train is not None:\n",
    "      train_items = np.frombuffer(\n",
    "          train_user_to_items[user_id], dtype=np.int32)\n",
    "      scores[train_items] = -1e6\n",
    "\n",
    "    \n",
    "\n",
    "    top_items = np.argsort(-scores)[:k]\n",
    "    num_test_items_in_k = sum(x in top_items for x in  test_items)\n",
    "    precision_values.append(num_test_items_in_k / k)\n",
    "    recall_values.append(num_test_items_in_k / len(test_items))\n",
    "    num_test_items.append(len((test_items)))\n",
    "    num_train_items.append(len(train_user_to_items[user_id]))\n",
    "    user_ids.append(user_id)\n",
    "\n",
    "  results_df_ = pd.DataFrame(\n",
    "    columns = ['CDSACCNO','precision@k', 'recall@k','num_test_items','portfolio_size'],\n",
    "    data = list(zip(user_ids, precision_values, recall_values, num_test_items, num_train_items))\n",
    "  )\n",
    "\n",
    "  return {\n",
    "      \"precision_at_k\": np.mean(precision_values),\n",
    "      \"recall_at_k\": np.mean(recall_values),\n",
    "      \"results_df_\" : results_df_\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5906/5906 [00:41<00:00, 143.02it/s]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(\n",
    "    retriever,\n",
    "    test_ds,\n",
    "    train_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDSACCNO</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>num_test_items</th>\n",
       "      <th>portfolio_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'HDF-74565-LI/00'</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'BMS-800262640-VN/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'COM-69742-LC/00'</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'BMS-861802000-VN/00'</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'HDF-743463188-VN/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>b'BMS-68660-LI/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>b'BMS-683600342-VN/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>b'CAS-86452-LI/00'</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>b'CMB-5826-LC/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>b'BMS-67319-LI/00'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5906 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CDSACCNO  precision@k  recall@k  num_test_items  \\\n",
       "0         b'HDF-74565-LI/00'          0.1  0.500000               2   \n",
       "1     b'BMS-800262640-VN/00'          0.0  0.000000               2   \n",
       "2         b'COM-69742-LC/00'          0.1  0.100000              10   \n",
       "3     b'BMS-861802000-VN/00'          0.3  0.214286              14   \n",
       "4     b'HDF-743463188-VN/00'          0.0  0.000000               2   \n",
       "...                      ...          ...       ...             ...   \n",
       "5901      b'BMS-68660-LI/00'          0.0  0.000000               3   \n",
       "5902  b'BMS-683600342-VN/00'          0.0  0.000000               3   \n",
       "5903      b'CAS-86452-LI/00'          0.1  0.333333               3   \n",
       "5904       b'CMB-5826-LC/00'          0.0  0.000000               2   \n",
       "5905      b'BMS-67319-LI/00'          0.0  0.000000               4   \n",
       "\n",
       "      portfolio_size  \n",
       "0                  9  \n",
       "1                 10  \n",
       "2                 38  \n",
       "3                 58  \n",
       "4                  9  \n",
       "...              ...  \n",
       "5901              10  \n",
       "5902              10  \n",
       "5903              10  \n",
       "5904               8  \n",
       "5905              18  \n",
       "\n",
       "[5906 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['results_df_']\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit Ratio - HOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hoo_(CDSACCNO, timestamp = 1664821800.0):\n",
    "\n",
    "    seen_items = train_df.loc[train_df.CDSACCNO == CDSACCNO].STOCKCODE.values.reshape(1, -1)\n",
    "\n",
    "    \n",
    "    _, recommendations = index.query_with_exclusions(\n",
    "    queries = (\n",
    "        tf.constant([CDSACCNO]),\n",
    "        tf.constant([timestamp])\n",
    "        ),\n",
    "    exclusions = seen_items\n",
    "    )\n",
    "\n",
    "    recommendations = [reco.decode('utf-8') for reco in recommendations.numpy().flatten()]\n",
    "    # print(f\"Recommendations for user %s: {recommendations}\" %(test_user))\n",
    "\n",
    "    names = np.array([code2name[code] for code in recommendations])\n",
    "    gics = np.array([code2gics[code] for code in recommendations])\n",
    "\n",
    "    user = {\n",
    "    'CDSACCNO' : np.array([CDSACCNO]),\n",
    "    'STOCKCODE' : np.array(recommendations).reshape(-1,10),\n",
    "    'GICS' : gics.reshape(-1,10),\n",
    "    'STOCKNAME' : names.reshape(-1,10)\n",
    "    }\n",
    "\n",
    "    pred_ratings = ranker(user)\n",
    "\n",
    "    recommendations_w_ratings = pd.DataFrame()\n",
    "    recommendations_w_ratings['STOCKCODE'] = recommendations\n",
    "    recommendations_w_ratings['PRED_RATING'] = pred_ratings.numpy().flatten()\n",
    "    recommendations_w_ratings = recommendations_w_ratings.sort_values( by = ['PRED_RATING'], ascending= False).reset_index(drop = True)\n",
    "\n",
    "    user_test_port_ = test_df.iloc[test_users_.groups[CDSACCNO]].sort_values('RATING', ascending = False)\n",
    "    recommendations_w_ratings = recommendations_w_ratings.join(user_test_port_.set_index('STOCKCODE'), on = 'STOCKCODE')[['STOCKCODE','PRED_RATING','RATING']]\n",
    "    \n",
    "    hit_ = 1 if (recommendations_w_ratings.RATING.isna().all()) == False else 0\n",
    "\n",
    "    return recommendations_w_ratings, hit_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5906 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5906/5906 [07:15<00:00, 13.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "test_timestamp = datetime.timestamp(datetime.now())\n",
    "\n",
    "hits_ = 0\n",
    "for user in tqdm(test_df.CDSACCNO.unique()):\n",
    "    _, hit_ = recommend_hoo_(user, test_timestamp)\n",
    "    hits_ += hit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.14764646122587"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hits_/test_df.CDSACCNO.nunique())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs - 11.03962072468676\n",
    "hoo - 11.395191330849983\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atrad_cars_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
