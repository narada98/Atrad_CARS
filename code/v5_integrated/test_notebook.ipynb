{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array\n",
    "import collections\n",
    "\n",
    "from typing import Dict, List, Optional, Text, Tuple\n",
    "\n",
    "def _create_feature_dict() -> Dict[Text, List[tf.Tensor]]:\n",
    "  return {\"STOCKCODE\": [], \"RATING\": [], \"GICS\": [], \"STOCKNAME\": [], \"UNIX_TS\": []}\n",
    "\n",
    "def _sample_list(\n",
    "    feature_lists: Dict[Text, List[tf.Tensor]],\n",
    "    num_examples_per_list: int,\n",
    "    random_state: Optional[np.random.RandomState] = None,\n",
    ") -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "  \"\"\"Function for sampling a list example from given feature lists.\"\"\"\n",
    "  if random_state is None:\n",
    "    random_state = np.random.RandomState()\n",
    "\n",
    "  sampled_indices = random_state.choice(\n",
    "      range(len(feature_lists[\"STOCKCODE\"])),\n",
    "      size=num_examples_per_list,\n",
    "      replace=False,\n",
    "  )\n",
    "  sampled_STOCKCODE = [\n",
    "      feature_lists[\"STOCKCODE\"][idx] for idx in sampled_indices\n",
    "  ]\n",
    "  sampled_RATING = [\n",
    "      feature_lists[\"RATING\"][idx]\n",
    "      for idx in sampled_indices\n",
    "  ]\n",
    "  sampled_GICS = [\n",
    "      feature_lists[\"GICS\"][idx] for idx in sampled_indices\n",
    "  ]\n",
    "  sampled_STOCKNAME = [\n",
    "      feature_lists[\"STOCKNAME\"][idx]\n",
    "      for idx in sampled_indices\n",
    "  ]\n",
    "  sampled_UNIX_TS = [\n",
    "      feature_lists[\"UNIX_TS\"][idx] for idx in sampled_indices\n",
    "  ]\n",
    "\n",
    "  return (\n",
    "      tf.stack(sampled_STOCKCODE, 0),\n",
    "      tf.stack(sampled_RATING, 0),\n",
    "      tf.stack(sampled_GICS, 0),\n",
    "      tf.stack(sampled_STOCKNAME, 0),\n",
    "      tf.stack(sampled_UNIX_TS, 0)\n",
    "  )\n",
    "\n",
    "\n",
    "def sample_listwise(\n",
    "    rating_dataset: tf.data.Dataset,\n",
    "    num_list_per_user: int = 10,\n",
    "    num_examples_per_list: int = 10,\n",
    "    seed: Optional[int] = None,\n",
    ") -> tf.data.Dataset:\n",
    "  \n",
    "  random_state = np.random.RandomState(seed)\n",
    "\n",
    "  example_lists_by_user = collections.defaultdict(_create_feature_dict)\n",
    "\n",
    "  movie_title_vocab = set()\n",
    "  for example in rating_dataset:\n",
    "    user_id = example[\"CDSACCNO\"].numpy()\n",
    "    example_lists_by_user[user_id][\"STOCKCODE\"].append(\n",
    "        example[\"STOCKCODE\"])\n",
    "    example_lists_by_user[user_id][\"RATING\"].append(\n",
    "        example[\"RATING\"])\n",
    "    example_lists_by_user[user_id][\"GICS\"].append(\n",
    "        example[\"GICS\"])\n",
    "    example_lists_by_user[user_id][\"STOCKNAME\"].append(\n",
    "        example[\"STOCKNAME\"])\n",
    "    example_lists_by_user[user_id][\"UNIX_TS\"].append(\n",
    "        example[\"UNIX_TS\"])\n",
    "    \n",
    "    movie_title_vocab.add(example[\"STOCKNAME\"].numpy())\n",
    "\n",
    "    \n",
    "\n",
    "  tensor_slices = {\"CDSACCNO\": [], \"STOCKCODE\": [], \"RATING\": [], \"GICS\": [], \"STOCKNAME\": [], \"UNIX_TS\": []}\n",
    "\n",
    "  for user_id, feature_lists in example_lists_by_user.items():\n",
    "    for _ in range(num_list_per_user):\n",
    "\n",
    "      # Drop the user if they don't have enough ratings.\n",
    "      if len(feature_lists[\"STOCKNAME\"]) < num_examples_per_list:\n",
    "        continue\n",
    "\n",
    "        '''sampled_STOCKCODE, 0),\n",
    "      tf.stack(sampled_RATING, 0),\n",
    "      tf.stack(sampled_GICS, 0),\n",
    "      tf.stack(sampled_STOCKNAME, 0),\n",
    "      tf.stack(sampled_UNIX_TS'''\n",
    "\n",
    "      sampled_STOCKCODE, sampled_RATING, sampled_GICS, sampled_STOCKNAME, sampled_UNIX_TS  = _sample_list(\n",
    "          feature_lists,\n",
    "          num_examples_per_list,\n",
    "          random_state=random_state,\n",
    "      )\n",
    "      tensor_slices[\"CDSACCNO\"].append(user_id)\n",
    "      tensor_slices[\"STOCKCODE\"].append(sampled_STOCKCODE)\n",
    "      tensor_slices[\"RATING\"].append(sampled_RATING)\n",
    "      tensor_slices[\"GICS\"].append(sampled_GICS)\n",
    "      tensor_slices[\"STOCKNAME\"].append(sampled_STOCKNAME)\n",
    "      tensor_slices[\"UNIX_TS\"].append(sampled_UNIX_TS)\n",
    "\n",
    "  return tf.data.Dataset.from_tensor_slices(tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios = tf.data.Dataset.load(\"../../data/portfolios_tfds_lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/train_lists\").cache() #data\\ratings_train\n",
    "test_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/test_lists\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-23479-LI/00'>,\n",
       "  'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       "  'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'RICHARD PIERIS AND COMPANY PLC'>,\n",
       "  'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Capital Goods'>,\n",
       "  'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'RICH'>,\n",
       "  'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1678213800.0>},\n",
       " 3077)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_ds)), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v1 = sample_listwise(\n",
    "    train_ds,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_v1 = sample_listwise(\n",
    "    test_ds,\n",
    "    num_list_per_user=1,\n",
    "    num_examples_per_list=10,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-23479-LI/00'>,\n",
       " 'STOCKCODE': <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'CIC', b'AMSL', b'RAL', b'REG', b'AEL'], dtype=object)>,\n",
       " 'RATING': <tf.Tensor: shape=(5,), dtype=float32, numpy=array([4., 2., 5., 5., 2.], dtype=float32)>,\n",
       " 'GICS': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'Materials', b'Health Care Equipment & Services',\n",
       "        b'Food Beverage & Tobacco', b'Consumer Durables & Apparel',\n",
       "        b'Capital Goods'], dtype=object)>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       " array([b'C I C HOLDINGS PLC', b'ASIRI SURGICAL HOSPITAL PLC',\n",
       "        b'RENUKA AGRI FOODS PLC', b'REGNIS (LANKA) PLC',\n",
       "        b'ACCESS ENGINEERING PLC'], dtype=object)>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       " array([1.6475418e+09, 1.6681050e+09, 1.7100954e+09, 1.7030970e+09,\n",
       "        1.6655994e+09], dtype=float32)>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5750"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v1.save(\"../../data/rating_lists_10/train\")\n",
    "test_v1.save(\"../../data/rating_lists_10/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_v1.take(1)))['STOCKCODE'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_v1.save(\"../../data/train_lists_ds\")\n",
    "# test_v1.save(\"../../data/test_lists_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\naradaw\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/train\").cache() #data\\ratings_train\n",
    "test_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/test\").cache()\n",
    "portfolios = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/portfolios_tfds\").cache()\n",
    "\n",
    "train_list_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/train_lists_ds\").batch(64).cache()\n",
    "test_list_ds = tf.data.Dataset.load(\"D:/dev work/recommender systems/Atrad_CARS/data/test_lists_ds\").batch(64).cache()\n",
    "\n",
    "items_ids = portfolios.batch(10000).map(lambda x: x[\"STOCKCODE\"])\n",
    "item_names = portfolios.batch(10000).map(lambda x: x[\"STOCKNAME\"])\n",
    "item_GICS = portfolios.batch(10000).map(lambda x: x[\"GICS\"])\n",
    "\n",
    "user_ids = portfolios.batch(10000).map(lambda x: x[\"CDSACCNO\"])\n",
    "\n",
    "unique_item_ids = np.unique(np.concatenate(list(items_ids)))\n",
    "unique_item_names = np.unique(np.concatenate(list(item_names)))\n",
    "unique_item_gics = np.unique(np.concatenate(list(item_GICS)))\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from item_embedding import ItemModel\n",
    "    from user_embedding import UserModel\n",
    "    \n",
    "    item_model = ItemModel(\n",
    "      unique_item_ids = unique_item_ids,\n",
    "      # unique_item_names = unique_item_names,\n",
    "      unique_item_gics = unique_item_gics\n",
    "    )\n",
    "\n",
    "    user_model = UserModel(\n",
    "      # use_timestamp = self.use_timestamp,\n",
    "      unique_user_ids = unique_user_ids, \n",
    "      # timestamps = self.timestamps, \n",
    "      # timestamp_buckets = self.timestamp_buckets\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDSACCNO': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'RPS-51649-LI/00', b'RPS-65961-LI/00'], dtype=object)>,\n",
       " 'GICS': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Consumer Services', b'Materials'], dtype=object)>,\n",
       " 'STOCKCODE': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'EDEN', b'HAYC'], dtype=object)>,\n",
       " 'RATING': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 0.], dtype=float32)>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'EDEN HOTEL LANKA PLC', b'HAYCARB PLC'], dtype=object)>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.6935066e+09, 1.6661178e+09], dtype=float32)>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = next(iter(train_ds.batch(2)))\n",
    "test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_inp = (test_batch['STOCKCODE'], test_batch['GICS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 32), dtype=float32, numpy=\n",
       "array([[-0.04609909,  0.03363004,  0.02220925,  0.04583086,  0.0479766 ,\n",
       "         0.00265212, -0.02566367, -0.03968347,  0.00273192,  0.00596799,\n",
       "        -0.03537735, -0.01152014, -0.02740055, -0.03847308,  0.03074887,\n",
       "         0.00746394,  0.02557604, -0.03605348,  0.03457588, -0.02633193,\n",
       "         0.00427165, -0.03910352, -0.0273193 , -0.00017543, -0.03689706,\n",
       "        -0.04243723, -0.04428256,  0.04085237, -0.0176506 ,  0.0199351 ,\n",
       "        -0.03132515, -0.03317406],\n",
       "       [-0.01962997,  0.00674096, -0.02899243,  0.00913846, -0.00501378,\n",
       "         0.02511619,  0.02637631,  0.00312997, -0.00820818,  0.0129496 ,\n",
       "        -0.04606619, -0.02202358, -0.00397959,  0.01801481, -0.03398924,\n",
       "        -0.00290748,  0.02743557, -0.02246892, -0.04797815, -0.02689838,\n",
       "        -0.03359759, -0.02839024,  0.04539985,  0.00563767,  0.03925189,\n",
       "         0.00502604, -0.0291852 ,  0.04716368, -0.01551688,  0.01839479,\n",
       "         0.0248143 ,  0.04978361]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ = item_model(item_inp)\n",
    "\n",
    "item_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'RPS-51649-LI/00', b'RPS-65961-LI/00'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_inp = (test_batch['CDSACCNO'])\n",
    "user_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'RPS-51649-LI/00', b'RPS-65961-LI/00'], dtype=object)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x) = user_inp\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 32), dtype=float32, numpy=\n",
       "array([[-0.04318248, -0.02557333, -0.04426644, -0.04888889,  0.02427775,\n",
       "        -0.04386343,  0.02423866, -0.04564811,  0.01165094,  0.0062684 ,\n",
       "        -0.02250808,  0.00321429,  0.03284386,  0.02103958,  0.04284323,\n",
       "        -0.01882521, -0.00179398,  0.02237108, -0.00775488, -0.02413813,\n",
       "         0.00760498,  0.0143137 ,  0.04713489, -0.03030295,  0.01238028,\n",
       "         0.04224949, -0.03005378,  0.02673508,  0.0179151 ,  0.04189148,\n",
       "         0.01856503, -0.03624506],\n",
       "       [ 0.01269467, -0.01087745,  0.04752555,  0.04394826, -0.02006676,\n",
       "         0.0152738 , -0.03520433, -0.00353701,  0.04113794, -0.04874184,\n",
       "         0.00096054,  0.02859712, -0.011659  ,  0.02957839, -0.02672126,\n",
       "        -0.04440721, -0.03383632, -0.0018695 , -0.01456378,  0.04407836,\n",
       "         0.00306519,  0.027582  ,  0.02934052,  0.01433052,  0.02391071,\n",
       "        -0.01924326,  0.00549962, -0.02390081, -0.0490739 ,  0.00514883,\n",
       "         0.01279065,  0.04338883]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ = user_model(user_inp)\n",
    "user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m list_length \u001b[38;5;241m=\u001b[39m \u001b[43mtest_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSTOCKCODE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m list_length\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:906\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[1;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    907\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "list_length = test_batch['STOCKCODE'].shape[1]\n",
    "list_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 32), dtype=float32, numpy=\n",
       "array([[[-0.04318248, -0.02557333, -0.04426644, -0.04888889,\n",
       "          0.02427775, -0.04386343,  0.02423866, -0.04564811,\n",
       "          0.01165094,  0.0062684 , -0.02250808,  0.00321429,\n",
       "          0.03284386,  0.02103958,  0.04284323, -0.01882521,\n",
       "         -0.00179398,  0.02237108, -0.00775488, -0.02413813,\n",
       "          0.00760498,  0.0143137 ,  0.04713489, -0.03030295,\n",
       "          0.01238028,  0.04224949, -0.03005378,  0.02673508,\n",
       "          0.0179151 ,  0.04189148,  0.01856503, -0.03624506]],\n",
       "\n",
       "       [[ 0.01269467, -0.01087745,  0.04752555,  0.04394826,\n",
       "         -0.02006676,  0.0152738 , -0.03520433, -0.00353701,\n",
       "          0.04113794, -0.04874184,  0.00096054,  0.02859712,\n",
       "         -0.011659  ,  0.02957839, -0.02672126, -0.04440721,\n",
       "         -0.03383632, -0.0018695 , -0.01456378,  0.04407836,\n",
       "          0.00306519,  0.027582  ,  0.02934052,  0.01433052,\n",
       "          0.02391071, -0.01924326,  0.00549962, -0.02390081,\n",
       "         -0.0490739 ,  0.00514883,  0.01279065,  0.04338883]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(user_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_re \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m----> 2\u001b[0m         tf\u001b[38;5;241m.\u001b[39mexpand_dims(user_, \u001b[38;5;241m1\u001b[39m), [\u001b[43mlist_length\u001b[49m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m user_re\n",
      "\u001b[1;31mNameError\u001b[0m: name 'list_length' is not defined"
     ]
    }
   ],
   "source": [
    "user_re = tf.repeat(\n",
    "        tf.expand_dims(user_, 1), [list_length], axis=1)\n",
    "user_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 5, 32]), TensorShape([2, 5, 16]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_re.shape, item_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 48), dtype=float32, numpy=\n",
       "array([[[-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "          0.03979154,  0.03620226, -0.01937484,  0.03311226,\n",
       "          0.01147978,  0.0093099 , -0.00974836, -0.00482779,\n",
       "          0.01623065,  0.00183672,  0.00651877, -0.0169461 ,\n",
       "          0.04624097,  0.00030952,  0.02818774, -0.00379416],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.03015504, -0.04399846, -0.00866134,  0.00601522,\n",
       "         -0.00071533, -0.01249503,  0.02293764,  0.01360965,\n",
       "         -0.01163197, -0.02358859,  0.01337222, -0.03650252,\n",
       "         -0.03902113,  0.02410716,  0.01964414, -0.01911411],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.01235435, -0.00602939, -0.00937619,  0.0364039 ,\n",
       "          0.04031854,  0.03945686,  0.0178032 ,  0.04763465,\n",
       "         -0.02128669,  0.02897033,  0.03444476,  0.03342701,\n",
       "          0.00624394, -0.04409353,  0.00519319, -0.01795617],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "          0.03428531,  0.03017886,  0.04840321, -0.0255578 ,\n",
       "         -0.04096984,  0.00083672, -0.04414078, -0.00994549,\n",
       "          0.0270129 , -0.01133798, -0.03096747, -0.0425156 ,\n",
       "         -0.00646298,  0.0064773 , -0.03074588, -0.02497333],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.01908041, -0.00651355,  0.00278138,  0.04807146,\n",
       "         -0.03102775, -0.03115836,  0.02238865,  0.00109873,\n",
       "         -0.01859944,  0.04079869, -0.00714887, -0.01145958,\n",
       "          0.02345551, -0.00884066, -0.00477856, -0.03787962]],\n",
       "\n",
       "       [[-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.04976692, -0.0475723 ,  0.00075904,  0.04366714,\n",
       "          0.00207019,  0.02637811, -0.03663816,  0.00330644,\n",
       "         -0.03237704, -0.02233803,  0.0224005 ,  0.01449612,\n",
       "          0.00868296,  0.00922314,  0.04479407,  0.01924289],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.03360798,  0.04366895, -0.01813953, -0.03770877,\n",
       "         -0.0028232 , -0.00654483, -0.00235602, -0.01499217,\n",
       "          0.04941985, -0.02536329,  0.04531801, -0.00815898,\n",
       "          0.0324275 ,  0.03336735,  0.00556761,  0.0362942 ],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "          0.04568323, -0.04614277, -0.04311414, -0.04712051,\n",
       "         -0.03219987, -0.01415882,  0.04663838, -0.02656263,\n",
       "          0.04920712,  0.02121483, -0.02513866, -0.02708598,\n",
       "         -0.04406551,  0.01560332, -0.0114537 , -0.01822016],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "          0.03500415,  0.01014537,  0.01959458, -0.01444892,\n",
       "          0.02380205, -0.03299959,  0.00969369,  0.04469306,\n",
       "          0.045134  ,  0.03797388, -0.00205636,  0.01394203,\n",
       "         -0.03658003,  0.02315725, -0.04104171,  0.04138112],\n",
       "        [-0.0003495 ,  0.00639479,  0.01359694,  0.04848125,\n",
       "         -0.00087982, -0.03632808, -0.0422799 , -0.04690582,\n",
       "         -0.03934409, -0.01662402, -0.02959414, -0.04046847,\n",
       "         -0.04506312, -0.01938169, -0.03839182,  0.04125197,\n",
       "         -0.00073742,  0.04836239,  0.01136787,  0.04344909,\n",
       "          0.03735143,  0.01791472,  0.02952674, -0.03846205,\n",
       "          0.0132929 , -0.04398532, -0.02443273, -0.00138602,\n",
       "         -0.04856403,  0.00433455, -0.0231949 , -0.04115522,\n",
       "         -0.01072918,  0.03371746, -0.01981474, -0.02676246,\n",
       "         -0.0217087 ,  0.01148324, -0.01038604,  0.00174222,\n",
       "          0.04166492,  0.01484574, -0.03808134,  0.0482095 ,\n",
       "         -0.04602152,  0.0246748 ,  0.00676202,  0.01062601]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_embeddings = tf.concat([user_re, item_], 2)\n",
    "concatenated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDSACCNO': <tf.Tensor: shape=(), dtype=string, numpy=b'RPS-51649-LI/00'>,\n",
       " 'GICS': <tf.Tensor: shape=(), dtype=string, numpy=b'Consumer Services'>,\n",
       " 'STOCKCODE': <tf.Tensor: shape=(), dtype=string, numpy=b'EDEN'>,\n",
       " 'RATING': <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(), dtype=string, numpy=b'EDEN HOTEL LANKA PLC'>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(), dtype=float32, numpy=1693506600.0>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "from item_embedding import ItemModel\n",
    "from user_embedding import UserModel\n",
    "\n",
    "def generate_embedding(item, item_model):\n",
    "  \n",
    "      item_id = item['STOCKCODE'] \n",
    "      item_name = item['STOCKNAME']\n",
    "      item_gics = item['GICS']\n",
    "\n",
    "      embedding = item_model([item_id, item_name, item_gics])\n",
    "      return embedding\n",
    "\n",
    "class Recommender(tfrs.models.Model):\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    # use_timestamp,\n",
    "    portfolios\n",
    "    ):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # self.use_timestamp = use_timestamp\n",
    "    self.portfolios = portfolios\n",
    "\n",
    "    self.items_ids = self.portfolios.batch(10000).map(lambda x: x[\"STOCKCODE\"])\n",
    "    self.item_names = self.portfolios.batch(10000).map(lambda x: x[\"STOCKNAME\"])\n",
    "    self.item_GICS = self.portfolios.batch(10000).map(lambda x: x[\"GICS\"])\n",
    "\n",
    "    self.user_ids = self.portfolios.batch(10000).map(lambda x: x[\"CDSACCNO\"])\n",
    "\n",
    "    self.unique_item_ids = np.unique(np.concatenate(list(self.items_ids)))\n",
    "    self.unique_item_names = np.unique(np.concatenate(list(self.item_names)))\n",
    "    self.unique_item_gics = np.unique(np.concatenate(list(self.item_GICS)))\n",
    "\n",
    "    self.unique_user_ids = np.unique(np.concatenate(list(self.user_ids)))\n",
    "\n",
    "    # need these to initialize timestamp embedding layers in future steps\n",
    "\n",
    "    # self.timestamps = np.concatenate(list(self.portfolios.map(lambda x: x[\"UNIX_TS\"]).batch(100)))\n",
    "\n",
    "    # self.max_timestamp = self.timestamps.max()\n",
    "    # self.min_timestamp = self.timestamps.min()\n",
    "\n",
    "    # self.timestamp_buckets = np.linspace(\n",
    "    #     self.min_timestamp, self.max_timestamp, num=1000,\n",
    "    # )\n",
    "\n",
    "    self.item_model = ItemModel(\n",
    "      unique_item_ids = self.unique_item_ids,\n",
    "      unique_item_names = self.unique_item_names,\n",
    "      unique_item_gics = self.unique_item_gics\n",
    "    )\n",
    "\n",
    "    self.user_model = UserModel(\n",
    "      # use_timestamp = self.use_timestamp,\n",
    "      unique_user_ids = self.unique_user_ids, \n",
    "      # timestamps = self.timestamps, \n",
    "      # timestamp_buckets = self.timestamp_buckets\n",
    "    )\n",
    "\n",
    "    self.score_model = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    self.ranking_task = tfrs.tasks.Ranking(\n",
    "      loss=tfr.keras.losses.ListMLELoss(),\n",
    "      metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "\n",
    "  def call(self, features) -> tf.Tensor:\n",
    "    user_embeddings = self.user_model(\n",
    "      (\n",
    "        features['CDSACCNO'],\n",
    "        # features['UNIX_TS']\n",
    "       )\n",
    "    )\n",
    "\n",
    "    item_embeddings = self.item_model(\n",
    "      (\n",
    "        features['STOCKCODE'],\n",
    "        # features['STOCKNAME'],\n",
    "        features['GICS']\n",
    "      )\n",
    "    )\n",
    "\n",
    "    # print('**********',features[\"STOCKCODE\"].shape, '**********')\n",
    "\n",
    "    list_length = features[\"STOCKCODE\"].shape[1] # changed this to 0. was 1\n",
    "\n",
    "    print('**********',user_embeddings.shape, '**********')\n",
    "\n",
    "    user_embedding_repeated = tf.repeat(\n",
    "        tf.expand_dims(user_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "    print('**********',user_embedding_repeated.shape, '**********')\n",
    "    print('**********',item_embeddings.shape, '**********')\n",
    "\n",
    "    concatenated_embeddings = tf.concat(\n",
    "        # [user_embedding_repeated, tf.expand_dims(item_embeddings, 0)], 2)\n",
    "        [user_embedding_repeated, item_embeddings], 2)\n",
    "\n",
    "    return self.score_model(concatenated_embeddings)\n",
    "    \n",
    "  def compute_loss(self, features, training = False):\n",
    "\n",
    "    labels = features.pop('RATING')\n",
    "\n",
    "    scores = self(features)\n",
    "\n",
    "    return self.ranking_task(\n",
    "      labels = labels,\n",
    "      predictions = tf.squeeze(scores, axis = 1)\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v2 = train_v1.batch(8)\n",
    "# next(iter(train_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CDSACCNO': <tf.Tensor: shape=(8,), dtype=string, numpy=\n",
       " array([b'RPS-23479-LI/00', b'RPS-23479-LI/00', b'RPS-23479-LI/00',\n",
       "        b'RPS-23479-LI/00', b'RPS-23479-LI/00', b'RPS-23479-LI/00',\n",
       "        b'RPS-23479-LI/00', b'RPS-23479-LI/00'], dtype=object)>,\n",
       " 'STOCKCODE': <tf.Tensor: shape=(8, 5), dtype=string, numpy=\n",
       " array([[b'CIC', b'AMSL', b'RAL', b'REG', b'AEL'],\n",
       "        [b'RICH', b'TAFL', b'ASIY', b'MHDL', b'HPWR'],\n",
       "        [b'HAYL', b'CIND', b'DIPD', b'RICH', b'AEL'],\n",
       "        [b'HEXP', b'DIST', b'TAFL', b'PINS', b'HAYL'],\n",
       "        [b'DIPD', b'PARQ', b'DIST', b'HEXP', b'HASU'],\n",
       "        [b'RICH', b'CIND', b'HPWR', b'TJL', b'PARQ'],\n",
       "        [b'DIAL', b'PINS', b'ALUM', b'DIST', b'KGAL'],\n",
       "        [b'CIC', b'HPWR', b'DIPD', b'AEL', b'SDB']], dtype=object)>,\n",
       " 'RATING': <tf.Tensor: shape=(8, 5), dtype=float32, numpy=\n",
       " array([[4., 2., 5., 5., 2.],\n",
       "        [3., 3., 2., 2., 3.],\n",
       "        [5., 3., 3., 3., 2.],\n",
       "        [3., 2., 3., 2., 5.],\n",
       "        [3., 2., 2., 3., 2.],\n",
       "        [3., 3., 3., 2., 2.],\n",
       "        [4., 2., 4., 2., 3.],\n",
       "        [4., 3., 3., 2., 3.]], dtype=float32)>,\n",
       " 'GICS': <tf.Tensor: shape=(8, 5), dtype=string, numpy=\n",
       " array([[b'Materials', b'Health Care Equipment & Services',\n",
       "         b'Food Beverage & Tobacco', b'Consumer Durables & Apparel',\n",
       "         b'Capital Goods'],\n",
       "        [b'Capital Goods', b'Food Beverage & Tobacco',\n",
       "         b'Diversified Financials', b'Real Estate', b'Utilities'],\n",
       "        [b'Capital Goods', b'Capital Goods', b'Materials',\n",
       "         b'Capital Goods', b'Capital Goods'],\n",
       "        [b'Consumer Durables & Apparel', b'Food Beverage & Tobacco',\n",
       "         b'Food Beverage & Tobacco', b'Insurance', b'Capital Goods'],\n",
       "        [b'Materials', b'Materials', b'Food Beverage & Tobacco',\n",
       "         b'Consumer Durables & Apparel', b'Insurance'],\n",
       "        [b'Capital Goods', b'Capital Goods', b'Utilities',\n",
       "         b'Consumer Durables & Apparel', b'Materials'],\n",
       "        [b'Telecommunication Services', b'Insurance', b'Materials',\n",
       "         b'Food Beverage & Tobacco', b'Food Beverage & Tobacco'],\n",
       "        [b'Materials', b'Utilities', b'Materials', b'Capital Goods',\n",
       "         b'Banks']], dtype=object)>,\n",
       " 'STOCKNAME': <tf.Tensor: shape=(8, 5), dtype=string, numpy=\n",
       " array([[b'C I C HOLDINGS PLC', b'ASIRI SURGICAL HOSPITAL PLC',\n",
       "         b'RENUKA AGRI FOODS PLC', b'REGNIS (LANKA) PLC',\n",
       "         b'ACCESS ENGINEERING PLC'],\n",
       "        [b'RICHARD PIERIS AND COMPANY PLC', b'THREE ACRE FARMS PLC',\n",
       "         b'ASIA SIYAKA COMMODITIES LIMITED',\n",
       "         b'MILLENNIUM HOUSING DEVELOPERS PLC', b'RESUS ENERGY PLC'],\n",
       "        [b'HAYLEYS PLC', b'CENTRAL INDUSTRIES PLC',\n",
       "         b'DIPPED PRODUCTS PLC', b'RICHARD PIERIS AND COMPANY PLC',\n",
       "         b'ACCESS ENGINEERING PLC'],\n",
       "        [b'HAYLEYS FIBRE PLC', b'DISTILLERIES COMPANY OF SRI LANKA PLC',\n",
       "         b'THREE ACRE FARMS PLC', b\"PEOPLE'S INSURANCE PLC\",\n",
       "         b'HAYLEYS PLC'],\n",
       "        [b'DIPPED PRODUCTS PLC', b'SWISSTEK (CEYLON) PLC',\n",
       "         b'DISTILLERIES COMPANY OF SRI LANKA PLC', b'HAYLEYS FIBRE PLC',\n",
       "         b'HNB ASSURANCE PLC'],\n",
       "        [b'RICHARD PIERIS AND COMPANY PLC', b'CENTRAL INDUSTRIES PLC',\n",
       "         b'RESUS ENERGY PLC', b'TEEJAY LANKA PLC',\n",
       "         b'SWISSTEK (CEYLON) PLC'],\n",
       "        [b'DIALOG AXIATA PLC', b\"PEOPLE'S INSURANCE PLC\", b'ALUMEX PLC',\n",
       "         b'DISTILLERIES COMPANY OF SRI LANKA PLC',\n",
       "         b'KEGALLE  PLANTATIONS  PLC'],\n",
       "        [b'C I C HOLDINGS PLC', b'RESUS ENERGY PLC',\n",
       "         b'DIPPED PRODUCTS PLC', b'ACCESS ENGINEERING PLC',\n",
       "         b'SANASA DEVELOPMENT BANK PLC']], dtype=object)>,\n",
       " 'UNIX_TS': <tf.Tensor: shape=(8, 5), dtype=float32, numpy=\n",
       " array([[1.6475418e+09, 1.6681050e+09, 1.7100954e+09, 1.7030970e+09,\n",
       "         1.6655994e+09],\n",
       "        [1.6782138e+09, 1.6695738e+09, 1.6511706e+09, 1.6678458e+09,\n",
       "         1.6801146e+09],\n",
       "        [1.6903962e+09, 1.6528122e+09, 1.6689690e+09, 1.6782138e+09,\n",
       "         1.6655994e+09],\n",
       "        [1.7092314e+09, 1.6485786e+09, 1.6695738e+09, 1.6786458e+09,\n",
       "         1.6903962e+09],\n",
       "        [1.6689690e+09, 1.6478010e+09, 1.6485786e+09, 1.7092314e+09,\n",
       "         1.6527258e+09],\n",
       "        [1.6782138e+09, 1.6528122e+09, 1.6801146e+09, 1.6655994e+09,\n",
       "         1.6478010e+09],\n",
       "        [1.7029242e+09, 1.6786458e+09, 1.6727706e+09, 1.6485786e+09,\n",
       "         1.6903962e+09],\n",
       "        [1.6475418e+09, 1.6801146e+09, 1.6689690e+09, 1.6655994e+09,\n",
       "         1.6910874e+09]], dtype=float32)>}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=(<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>,). Consider rewriting this model with the Functional API.\n",
      "********** (1, None, 32) **********\n",
      "********** (1, 5, None, 32) **********\n",
      "********** (None, 5, 16) **********\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_6416\\3972399412.py\", line 123, in compute_loss\n        scores = self(features)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_file6zchcepq.py\", line 17, in tf__call\n        concatenated_embeddings = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(user_embedding_repeated), ag__.ld(item_embeddings)], 2), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'recommender_9' (type Recommender).\n    \n    in user code:\n    \n        File \"d:\\dev work\\recommender systems\\Atrad_CARS\\code\\v3_listwise\\recommender.py\", line 113, in call  *\n            concatenated_embeddings = tf.concat(\n    \n        ValueError: Shape must be rank 4 but is rank 3 for '{{node recommender_9/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](recommender_9/Repeat/Reshape_1, recommender_9/item_model_14/concat/concat, recommender_9/concat/axis)' with input shapes: [1,5,?,32], [?,5,16], [].\n    \n    \n    Call arguments received by layer 'recommender_9' (type Recommender):\n      â€¢ features={'CDSACCNO': 'tf.Tensor(shape=(None,), dtype=string)', 'STOCKCODE': 'tf.Tensor(shape=(None, 5), dtype=string)', 'GICS': 'tf.Tensor(shape=(None, 5), dtype=string)', 'STOCKNAME': 'tf.Tensor(shape=(None, 5), dtype=string)', 'UNIX_TS': 'tf.Tensor(shape=(None, 5), dtype=float32)'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Recommender(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# use_timestamp = True,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     portfolios \u001b[38;5;241m=\u001b[39m portfolios\n\u001b[0;32m      4\u001b[0m     )\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_v2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexjonf8i3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;66;03m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[140], line 123\u001b[0m, in \u001b[0;36mRecommender.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, features, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    121\u001b[0m   labels \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRATING\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 123\u001b[0m   scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranking_task(\n\u001b[0;32m    126\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels,\n\u001b[0;32m    127\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(scores, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    128\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6zchcepq.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     15\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(user_embedding_repeated)\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(item_embeddings)\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**********\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m concatenated_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mld(user_embedding_repeated), ag__\u001b[38;5;241m.\u001b[39mld(item_embeddings)], \u001b[38;5;241m2\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\ipykernel_6416\\3972399412.py\", line 123, in compute_loss\n        scores = self(features)\n    File \"c:\\Users\\bpadmin\\anaconda3\\envs\\atrad_cars_v2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\naradaw\\AppData\\Local\\Temp\\__autograph_generated_file6zchcepq.py\", line 17, in tf__call\n        concatenated_embeddings = ag__.converted_call(ag__.ld(tf).concat, ([ag__.ld(user_embedding_repeated), ag__.ld(item_embeddings)], 2), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'recommender_9' (type Recommender).\n    \n    in user code:\n    \n        File \"d:\\dev work\\recommender systems\\Atrad_CARS\\code\\v3_listwise\\recommender.py\", line 113, in call  *\n            concatenated_embeddings = tf.concat(\n    \n        ValueError: Shape must be rank 4 but is rank 3 for '{{node recommender_9/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](recommender_9/Repeat/Reshape_1, recommender_9/item_model_14/concat/concat, recommender_9/concat/axis)' with input shapes: [1,5,?,32], [?,5,16], [].\n    \n    \n    Call arguments received by layer 'recommender_9' (type Recommender):\n      â€¢ features={'CDSACCNO': 'tf.Tensor(shape=(None,), dtype=string)', 'STOCKCODE': 'tf.Tensor(shape=(None, 5), dtype=string)', 'GICS': 'tf.Tensor(shape=(None, 5), dtype=string)', 'STOCKNAME': 'tf.Tensor(shape=(None, 5), dtype=string)', 'UNIX_TS': 'tf.Tensor(shape=(None, 5), dtype=float32)'}\n"
     ]
    }
   ],
   "source": [
    "model = Recommender(\n",
    "    # use_timestamp = True,\n",
    "    portfolios = portfolios\n",
    "    )\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "model.fit(\n",
    "    train_v2, \n",
    "    epochs=20, \n",
    "    verbose = 1,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
